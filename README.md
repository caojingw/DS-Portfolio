# Data Science Portfolio - James Cao

This Portfolio consists of all the Data Science projects I have done for academic, self-learning and hobby purposes. This portfolio also contains my Achievements, skills, and certificates. It is updated on a regular basis.

- **Email**: [james.cao1@outlook.com](james.cao1@outlook.com)
- **LinkedIn**: [linkedin.com/jamescao1225](https://www.linkedin.com/in/jamescao1225/)

## Achievements

- Scotiabank AI-Kathon Winner

## Projects

<img align="left" width="250" height="150" src="Images\amazon.png"> **[Amazon Review Helpful Prediction](https://github.com/caojingw/Amazon_Review)**

Developed an NLP model to predict Amazon review helpfulness using Databricks/PySpark, achieving second place among 12 teams. We used Azure Databricks (which is based on Apache Spark) to analyze and model a large, textual dataset. The goals of this project are threefold:
- Learn how to use Spark/Databricks to work with Big Data from the real world.
- Further your knowledge and experience of building ML models using textual features
- Estimate the costs of Big Data projects in the cloud.


#

<img align="left" width="250" height="150" src="Images\waterpump.png"> **[Pump It Up: Data Mining the Water Table](https://github.com/caojingw/pump-it-up)**

The objective of this project is to use data from Taarifa and the Tanzanian Ministry of Water to predict which pumps are functional, which need some repairs, and which don't work at all? We Scored in the top 1% out of 3000+ teams in predicting pump functionality, utilizing a voting ensemble method of LightGBM, XGBoost, CatBoost, and Random Forest.                                                                                    

#

<img align="left" width="250" height="150" src="Images\houseprice.jpeg"> **[House Price Prediction](https://github.com/caojingw/House-Prices-Advanced-Regression-Techniques)**
 
•	Used Lasso and Ridge regressions to predict the house price to get the top 20% on the leaderboard.
•	Dealt with missing instances, feature engineering and normalization to minimize the RSME by 10%
